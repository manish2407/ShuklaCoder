{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_deblurring.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgxvE1frM5CHr0wcH32cYw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manish2407/ShuklaCoder/blob/master/Image_deblurring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "os.makedirs('../my_project/input/gaussian_blurred', exist_ok=True)\n",
        "src_dir = '../my_project/input/sharp'\n",
        "images = os.listdir(src_dir)\n",
        "dst_dir = '../my_project/input/gaussian_blurred'"
      ],
      "metadata": {
        "id": "K7yEozks57RK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "03cbe810-39ac-432b-ec01-76e75f2bac8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-f94e5d5738f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../my_project/input/gaussian_blurred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msrc_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../my_project/input/sharp'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdst_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../my_project/input/gaussian_blurred'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../my_project/input/sharp'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding Gaussian Blurring\n"
      ],
      "metadata": {
        "id": "7MYNoDmRC6D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, img in tqdm(enumerate(images), total=len(images)):\n",
        "    img = cv2.imread(f\"{src_dir}/{images[i]}\", cv2.IMREAD_COLOR)\n",
        "    # add gaussian blurring\n",
        "    blur = cv2.GaussianBlur(img, (31, 31), 0)\n",
        "    cv2.imwrite(f\"{dst_dir}/{images[i]}\", blur)\n",
        "print('DONE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "YYknE3SEC_ea",
        "outputId": "6c37af57-bb1f-4929-a14b-8500ca743084"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-42d398cce9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{src_dir}/{images[i]}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# add gaussian blurring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mblur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{dst_dir}/{images[i]}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add_gaussian_blur.py\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "os.makedirs('../my_project/input/gaussian_blurred', exist_ok=True)\n",
        "src_dir = '../my_project/input/sharp'\n",
        "images = os.listdir(src_dir)\n",
        "dst_dir = '../my_project/input/gaussian_blurred'\n",
        "for i, img in tqdm(enumerate(images), total=len(images)):\n",
        "    img = cv2.imread(f\"{src_dir}/{images[i]}\", cv2.IMREAD_COLOR)\n",
        "    # add gaussian blurring\n",
        "    blur = cv2.GaussianBlur(img, (31, 31), 0)\n",
        "    cv2.imwrite(f\"{dst_dir}/{images[i]}\", blur)\n",
        "print('DONE')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiMJGvvEEkWg",
        "outputId": "ab7ef883-56e8-4050-9bc2-a66c78df11ad"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add_gaussian_blur.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/add_gaussian_blur.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pg9zTWPqFa7n",
        "outputId": "ad851603-cf36-46c1-a915-9f55dbbc47e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/add_gaussian_blur.py\", line 7, in <module>\n",
            "    images = os.listdir(src_dir)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../my_project/input/sharp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deblur.py\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.utils import save_image\n",
        "from sklearn.model_selection import train_test_split\n",
        "# constructing the argument parser\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('-e', '--epochs', type=int, default=40, \n",
        "            help='number of epochs to train the model for')\n",
        "args = vars(parser.parse_args())\n",
        "def save_decoded_image(img, name):\n",
        "    img = img.view(img.size(0), 3, 224, 224)\n",
        "    save_image(img, name)\n",
        "# helper functions\n",
        "image_dir = '../outputs/saved_images'\n",
        "os.makedirs(image_dir, exist_ok=True)\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "batch_size = 2\n",
        "gauss_blur = os.listdir('../input/gaussian_blurred')\n",
        "gauss_blur.sort()\n",
        "sharp = os.listdir('../input/sharp')\n",
        "sharp.sort()\n",
        "x_blur = []\n",
        "for i in range(len(gauss_blur)):\n",
        "    x_blur.append(gauss_blur[i])\n",
        "y_sharp = []\n",
        "for i in range(len(sharp)):\n",
        "    y_sharp.append(sharp[i])\n",
        "(x_train, x_val, y_train, y_val) = train_test_split(x_blur, y_sharp, test_size=0.25)\n",
        "print(f\"Train data instances: {len(x_train)}\")\n",
        "print(f\"Validation data instances: {len(x_val)}\")\n",
        "# define transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "class DeblurDataset(Dataset):\n",
        "    def __init__(self, blur_paths, sharp_paths=None, transforms=None):\n",
        "        self.X = blur_paths\n",
        "        self.y = sharp_paths\n",
        "        self.transforms = transforms\n",
        "         \n",
        "    def __len__(self):\n",
        "        return (len(self.X))\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        blur_image = cv2.imread(f\"../input/gaussian_blurred/{self.X[i]}\")\n",
        "        \n",
        "        if self.transforms:\n",
        "            blur_image = self.transforms(blur_image)\n",
        "            \n",
        "        if self.y is not None:\n",
        "            sharp_image = cv2.imread(f\"../input/sharp/{self.y[i]}\")\n",
        "            sharp_image = self.transforms(sharp_image)\n",
        "            return (blur_image, sharp_image)\n",
        "        else:\n",
        "            return blur_image\n",
        "train_data = DeblurDataset(x_train, y_train, transform)\n",
        "val_data = DeblurDataset(x_val, y_val, transform)\n",
        " \n",
        "trainloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "valloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
        "class DeblurCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DeblurCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=2)\n",
        "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x\n",
        "model = DeblurCNN().to(device)\n",
        "print(model)\n",
        "# the loss function\n",
        "criterion = nn.MSELoss()\n",
        "# the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau( \n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        patience=5,\n",
        "        factor=0.5,\n",
        "        verbose=True\n",
        "    )\n",
        "def fit(model, dataloader, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data)/dataloader.batch_size)):\n",
        "        blur_image = data[0]\n",
        "        sharp_image = data[1]\n",
        "        blur_image = blur_image.to(device)\n",
        "        sharp_image = sharp_image.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(blur_image)\n",
        "        loss = criterion(outputs, sharp_image)\n",
        "        # backpropagation\n",
        "        loss.backward()\n",
        "        # update the parameters\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    train_loss = running_loss/len(dataloader.dataset)\n",
        "    print(f\"Train Loss: {train_loss:.5f}\")\n",
        "    \n",
        "    return train_loss\n",
        "def validate(model, dataloader, epoch):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data)/dataloader.batch_size)):\n",
        "            blur_image = data[0]\n",
        "            sharp_image = data[1]\n",
        "            blur_image = blur_image.to(device)\n",
        "            sharp_image = sharp_image.to(device)\n",
        "            outputs = model(blur_image)\n",
        "            loss = criterion(outputs, sharp_image)\n",
        "            running_loss += loss.item()\n",
        "            if epoch == 0 and i == int((len(val_data)/dataloader.batch_size)-1):\n",
        "                save_decoded_image(sharp_image.cpu().data, name=f\"../outputs/saved_images/sharp{epoch}.jpg\")\n",
        "                save_decoded_image(blur_image.cpu().data, name=f\"../outputs/saved_images/blur{epoch}.jpg\")\n",
        "            if i == int((len(val_data)/dataloader.batch_size)-1):\n",
        "                save_decoded_image(outputs.cpu().data, name=f\"../outputs/saved_images/val_deblurred{epoch}.jpg\")\n",
        "        val_loss = running_loss/len(dataloader.dataset)\n",
        "        print(f\"Val Loss: {val_loss:.5f}\")\n",
        "        \n",
        "        return val_loss\n",
        "train_loss  = []\n",
        "val_loss = []\n",
        "start = time.time()\n",
        "for epoch in range(args['epochs']):\n",
        "    print(f\"Epoch {epoch+1} of {args['epochs']}\")\n",
        "    train_epoch_loss = fit(model, trainloader, epoch)\n",
        "    val_epoch_loss = validate(model, valloader, epoch)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    scheduler.step(val_epoch_loss)\n",
        "end = time.time()\n",
        "print(f\"Took {((end-start)/60):.3f} minutes to train\")\n",
        "# loss plots\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.plot(train_loss, color='orange', label='train loss')\n",
        "plt.plot(val_loss, color='red', label='validataion loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('../outputs/loss.png')\n",
        "plt.show()\n",
        "# save the model to disk\n",
        "print('Saving model...')\n",
        "torch.save(model.state_dict(), '../outputs/model.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_1FJ8SKEy8r",
        "outputId": "efa18f95-a334-4ca5-8ac0-b7ce37e1daf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing deblur.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/deblur.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5iCQL-BHH3A",
        "outputId": "d9b43b15-d1c3-479e-8aee-331d7865b6ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/deblur.py\", line 34, in <module>\n",
            "    sharp = os.listdir('../input/sharp')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '../input/sharp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "daJcs9HXHR7s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}